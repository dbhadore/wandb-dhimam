{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a288181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc88f37",
   "metadata": {},
   "source": [
    "#### Install Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec95db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034458ba",
   "metadata": {},
   "source": [
    "#### Login wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d471bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfe003",
   "metadata": {},
   "source": [
    "#### Load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6fe4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.train --output regression.train --silent\n",
    "!curl https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.test --output regression.test --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4789b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('regression.test', header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09a98c",
   "metadata": {},
   "source": [
    "#### 1. wandb.init : initialize wandb\n",
    "#### 2. wandb_callback(): for integration\n",
    "#### 3. wandb.log : log results to be seen in UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccea4ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">restful-plant-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dbhadore/gbm-dhiman\" target=\"_blank\">https://wandb.ai/dbhadore/gbm-dhiman</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dbhadore/gbm-dhiman/runs/2d9ev6et\" target=\"_blank\">https://wandb.ai/dbhadore/gbm-dhiman/runs/2d9ev6et</a><br/>\n",
       "                Run data is saved locally in <code>C:\\code\\wandb\\wandb\\run-20210529_200548-2d9ev6et</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[1]\tvalidation's rmse: 0.493229\tvalidation's l2: 0.243275\tvalidation's l1: 0.492165\tvalidation's huber: 0.121637\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalidation's rmse: 0.488682\tvalidation's l2: 0.23881\tvalidation's l1: 0.487438\tvalidation's huber: 0.119405\n",
      "[3]\tvalidation's rmse: 0.483228\tvalidation's l2: 0.233509\tvalidation's l1: 0.48156\tvalidation's huber: 0.116755\n",
      "[4]\tvalidation's rmse: 0.478201\tvalidation's l2: 0.228676\tvalidation's l1: 0.475989\tvalidation's huber: 0.114338\n",
      "[5]\tvalidation's rmse: 0.475061\tvalidation's l2: 0.225683\tvalidation's l1: 0.472263\tvalidation's huber: 0.112842\n",
      "[6]\tvalidation's rmse: 0.471554\tvalidation's l2: 0.222363\tvalidation's l1: 0.468271\tvalidation's huber: 0.111182\n",
      "[7]\tvalidation's rmse: 0.467668\tvalidation's l2: 0.218713\tvalidation's l1: 0.463499\tvalidation's huber: 0.109357\n",
      "[8]\tvalidation's rmse: 0.464196\tvalidation's l2: 0.215478\tvalidation's l1: 0.459052\tvalidation's huber: 0.107739\n",
      "[9]\tvalidation's rmse: 0.460873\tvalidation's l2: 0.212404\tvalidation's l1: 0.454644\tvalidation's huber: 0.106202\n",
      "[10]\tvalidation's rmse: 0.457827\tvalidation's l2: 0.209605\tvalidation's l1: 0.450419\tvalidation's huber: 0.104803\n",
      "[11]\tvalidation's rmse: 0.455803\tvalidation's l2: 0.207756\tvalidation's l1: 0.447345\tvalidation's huber: 0.103878\n",
      "[12]\tvalidation's rmse: 0.453917\tvalidation's l2: 0.206041\tvalidation's l1: 0.444361\tvalidation's huber: 0.10302\n",
      "[13]\tvalidation's rmse: 0.452494\tvalidation's l2: 0.204751\tvalidation's l1: 0.441823\tvalidation's huber: 0.102375\n",
      "[14]\tvalidation's rmse: 0.451249\tvalidation's l2: 0.203626\tvalidation's l1: 0.439389\tvalidation's huber: 0.101813\n",
      "[15]\tvalidation's rmse: 0.449684\tvalidation's l2: 0.202216\tvalidation's l1: 0.43679\tvalidation's huber: 0.101108\n",
      "[16]\tvalidation's rmse: 0.447944\tvalidation's l2: 0.200653\tvalidation's l1: 0.434028\tvalidation's huber: 0.100327\n",
      "[17]\tvalidation's rmse: 0.446485\tvalidation's l2: 0.199349\tvalidation's l1: 0.431981\tvalidation's huber: 0.0996744\n",
      "[18]\tvalidation's rmse: 0.444446\tvalidation's l2: 0.197532\tvalidation's l1: 0.428983\tvalidation's huber: 0.0987661\n",
      "[19]\tvalidation's rmse: 0.443174\tvalidation's l2: 0.196403\tvalidation's l1: 0.426567\tvalidation's huber: 0.0982017\n",
      "[20]\tvalidation's rmse: 0.44201\tvalidation's l2: 0.195373\tvalidation's l1: 0.424477\tvalidation's huber: 0.0976865\n",
      "[21]\tvalidation's rmse: 0.441295\tvalidation's l2: 0.194742\tvalidation's l1: 0.422688\tvalidation's huber: 0.0973708\n",
      "[22]\tvalidation's rmse: 0.439941\tvalidation's l2: 0.193548\tvalidation's l1: 0.420331\tvalidation's huber: 0.0967739\n",
      "[23]\tvalidation's rmse: 0.439391\tvalidation's l2: 0.193064\tvalidation's l1: 0.418848\tvalidation's huber: 0.0965321\n",
      "[24]\tvalidation's rmse: 0.438226\tvalidation's l2: 0.192042\tvalidation's l1: 0.417103\tvalidation's huber: 0.0960209\n",
      "[25]\tvalidation's rmse: 0.437008\tvalidation's l2: 0.190976\tvalidation's l1: 0.414897\tvalidation's huber: 0.0954878\n",
      "[26]\tvalidation's rmse: 0.43557\tvalidation's l2: 0.189721\tvalidation's l1: 0.412469\tvalidation's huber: 0.0948605\n",
      "[27]\tvalidation's rmse: 0.434209\tvalidation's l2: 0.188537\tvalidation's l1: 0.410204\tvalidation's huber: 0.0942687\n",
      "[28]\tvalidation's rmse: 0.433227\tvalidation's l2: 0.187685\tvalidation's l1: 0.408356\tvalidation's huber: 0.0938427\n",
      "[29]\tvalidation's rmse: 0.431863\tvalidation's l2: 0.186506\tvalidation's l1: 0.405872\tvalidation's huber: 0.0932529\n",
      "[30]\tvalidation's rmse: 0.43093\tvalidation's l2: 0.185701\tvalidation's l1: 0.403879\tvalidation's huber: 0.0928503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30]\tvalidation's rmse: 0.43093\tvalidation's l2: 0.185701\tvalidation's l1: 0.403879\tvalidation's huber: 0.0928503\n",
      "The rmse of prediction is: 0.43093000462442216\n"
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['rmse', 'l2', 'l1', 'huber'],\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "wandb.init(project='gbm-dhiman', config=params);\n",
    "\n",
    "# train \n",
    "# add lightgbm callback\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=30,\n",
    "                valid_sets=lgb_eval,\n",
    "                valid_names=('validation'),\n",
    "                callbacks=[wandb_callback()],\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "wandb.log({'Prediction': mean_squared_error(y_test, y_pred) ** 0.5})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
