{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a288181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec95db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d471bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: dbhadore (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6fe4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.train --output regression.train --silent\n",
    "!curl https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.test --output regression.test --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4789b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('regression.test', header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccea4ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">divine-pond-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dbhadore/my-lightgbm-integration-dhiman\" target=\"_blank\">https://wandb.ai/dbhadore/my-lightgbm-integration-dhiman</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dbhadore/my-lightgbm-integration-dhiman/runs/o90fad27\" target=\"_blank\">https://wandb.ai/dbhadore/my-lightgbm-integration-dhiman/runs/o90fad27</a><br/>\n",
       "                Run data is saved locally in <code>C:\\code\\wandb\\wandb\\run-20210529_111837-o90fad27</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[1]\tvalidation's rmse: 0.494041\tvalidation's l2: 0.244076\tvalidation's l1: 0.493018\tvalidation's huber: 0.122038\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalidation's rmse: 0.490201\tvalidation's l2: 0.240297\tvalidation's l1: 0.489056\tvalidation's huber: 0.120148\n",
      "[3]\tvalidation's rmse: 0.485523\tvalidation's l2: 0.235733\tvalidation's l1: 0.484089\tvalidation's huber: 0.117866\n",
      "[4]\tvalidation's rmse: 0.480991\tvalidation's l2: 0.231352\tvalidation's l1: 0.479088\tvalidation's huber: 0.115676\n",
      "[5]\tvalidation's rmse: 0.478476\tvalidation's l2: 0.228939\tvalidation's l1: 0.476159\tvalidation's huber: 0.11447\n",
      "[6]\tvalidation's rmse: 0.475321\tvalidation's l2: 0.22593\tvalidation's l1: 0.472664\tvalidation's huber: 0.112965\n",
      "[7]\tvalidation's rmse: 0.471715\tvalidation's l2: 0.222515\tvalidation's l1: 0.468425\tvalidation's huber: 0.111258\n",
      "[8]\tvalidation's rmse: 0.468582\tvalidation's l2: 0.219569\tvalidation's l1: 0.464594\tvalidation's huber: 0.109785\n",
      "[9]\tvalidation's rmse: 0.465618\tvalidation's l2: 0.2168\tvalidation's l1: 0.460795\tvalidation's huber: 0.1084\n",
      "[10]\tvalidation's rmse: 0.463002\tvalidation's l2: 0.214371\tvalidation's l1: 0.457276\tvalidation's huber: 0.107186\n",
      "[11]\tvalidation's rmse: 0.460421\tvalidation's l2: 0.211988\tvalidation's l1: 0.453923\tvalidation's huber: 0.105994\n",
      "[12]\tvalidation's rmse: 0.458546\tvalidation's l2: 0.210264\tvalidation's l1: 0.451235\tvalidation's huber: 0.105132\n",
      "[13]\tvalidation's rmse: 0.457084\tvalidation's l2: 0.208926\tvalidation's l1: 0.448992\tvalidation's huber: 0.104463\n",
      "[14]\tvalidation's rmse: 0.455415\tvalidation's l2: 0.207403\tvalidation's l1: 0.44634\tvalidation's huber: 0.103701\n",
      "[15]\tvalidation's rmse: 0.453884\tvalidation's l2: 0.20601\tvalidation's l1: 0.444016\tvalidation's huber: 0.103005\n",
      "[16]\tvalidation's rmse: 0.452158\tvalidation's l2: 0.204447\tvalidation's l1: 0.441362\tvalidation's huber: 0.102223\n",
      "[17]\tvalidation's rmse: 0.450236\tvalidation's l2: 0.202712\tvalidation's l1: 0.43891\tvalidation's huber: 0.101356\n",
      "[18]\tvalidation's rmse: 0.448403\tvalidation's l2: 0.201066\tvalidation's l1: 0.436192\tvalidation's huber: 0.100533\n",
      "[19]\tvalidation's rmse: 0.44699\tvalidation's l2: 0.1998\tvalidation's l1: 0.433884\tvalidation's huber: 0.0999001\n",
      "[20]\tvalidation's rmse: 0.445043\tvalidation's l2: 0.198063\tvalidation's l1: 0.431129\tvalidation's huber: 0.0990315\n",
      "[21]\tvalidation's rmse: 0.443938\tvalidation's l2: 0.197081\tvalidation's l1: 0.429092\tvalidation's huber: 0.0985403\n",
      "[22]\tvalidation's rmse: 0.443027\tvalidation's l2: 0.196273\tvalidation's l1: 0.427252\tvalidation's huber: 0.0981366\n",
      "[23]\tvalidation's rmse: 0.441971\tvalidation's l2: 0.195338\tvalidation's l1: 0.425198\tvalidation's huber: 0.0976691\n",
      "[24]\tvalidation's rmse: 0.440708\tvalidation's l2: 0.194223\tvalidation's l1: 0.423458\tvalidation's huber: 0.0971117\n",
      "[25]\tvalidation's rmse: 0.439554\tvalidation's l2: 0.193207\tvalidation's l1: 0.421293\tvalidation's huber: 0.0966037\n",
      "[26]\tvalidation's rmse: 0.438623\tvalidation's l2: 0.19239\tvalidation's l1: 0.419415\tvalidation's huber: 0.0961949\n",
      "[27]\tvalidation's rmse: 0.437074\tvalidation's l2: 0.191033\tvalidation's l1: 0.417054\tvalidation's huber: 0.0955166\n",
      "[28]\tvalidation's rmse: 0.436193\tvalidation's l2: 0.190265\tvalidation's l1: 0.415473\tvalidation's huber: 0.0951324\n",
      "[29]\tvalidation's rmse: 0.434961\tvalidation's l2: 0.189191\tvalidation's l1: 0.413446\tvalidation's huber: 0.0945955\n",
      "[30]\tvalidation's rmse: 0.434213\tvalidation's l2: 0.188541\tvalidation's l1: 0.411844\tvalidation's huber: 0.0942704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30]\tvalidation's rmse: 0.434213\tvalidation's l2: 0.188541\tvalidation's l1: 0.411844\tvalidation's huber: 0.0942704\n",
      "The rmse of prediction is: 0.43421275319941804\n"
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['rmse', 'l2', 'l1', 'huber'],\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "wandb.init(project='my-lightgbm-integration-dhiman', config=params);\n",
    "\n",
    "# train \n",
    "# add lightgbm callback\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=30,\n",
    "                valid_sets=lgb_eval,\n",
    "                valid_names=('validation'),\n",
    "                callbacks=[wandb_callback()],\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "wandb.log({'rmse_prediction': mean_squared_error(y_test, y_pred) ** 0.5})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
